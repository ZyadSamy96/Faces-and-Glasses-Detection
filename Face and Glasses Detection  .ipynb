{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f28b5a",
   "metadata": {},
   "source": [
    "# Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad38a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d93bd",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7be09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    return cv.imread('11.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3222437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescal_frame(frame,dimensions):\n",
    "\n",
    "    return cv2.resize(frame,dimensions,interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d11e4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_put(frame,text):\n",
    "    printed=f' Prediction is :{text}'\n",
    "    org = (5, 20)\n",
    "    fontScale = 0.5\n",
    "    color = (255, 255, 255)\n",
    "    thickness = 2\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    #                   image  text      orgin  font_type\n",
    "    image = cv2.putText(frame,  printed,    org,    font,\n",
    "    #                font_scale,   color,   thickness  ,lineType  ,bottomLeftOrigin\n",
    "                         fontScale, color, thickness,   cv2.LINE_AA, False)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ddf31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(prediction):\n",
    "    classes_name=['Glasses','No Glasses']\n",
    "\n",
    "    return classes_name[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d04fb0",
   "metadata": {},
   "source": [
    "# Face Detection Using Haar Cascades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81a3bf",
   "metadata": {},
   "source": [
    "## - Testing on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8372a61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 person\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('11.jpg')\n",
    "cv2.imshow('Male Face org',img)\n",
    "\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Male Face gray',gray)\n",
    "\n",
    "har_file=cv2.CascadeClassifier('Har.xml')\n",
    "face_rect=har_file.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=1)\n",
    "print(f\"There are {len(face_rect)} person\")\n",
    "\n",
    "\n",
    "for (x,y,w,h) in face_rect:\n",
    "    cv2.rectangle(img,(x,y) , (x+w, y+h) ,(255,0,0),thickness=3)\n",
    "cv2.imshow('Detecyed Face org',img)\n",
    "\n",
    "\n",
    "cv2.waitKey(15000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3972b",
   "metadata": {},
   "source": [
    "## - On Live Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c28cd1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n",
      "There are 1 person\n"
     ]
    }
   ],
   "source": [
    "har_file=cv2.CascadeClassifier('Har.xml')\n",
    "\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame=capture.read()\n",
    "    frame=cv2.flip(frame,1)\n",
    "    frame=rescal_frame(frame,(256,256))\n",
    "    if not ret:\n",
    "        break\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    gauss = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "#     _, thresh = cv2.threshold(gauss, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "#     thresh= cv2.dilate(thresh,(3,3),2)\n",
    "    \n",
    "    face_rect=har_file.detectMultiScale(gauss,scaleFactor=1.1,minNeighbors=3)\n",
    "    print(f\"There are {len(face_rect)} person\")\n",
    "    for (x,y,w,h) in face_rect:\n",
    "        cv2.rectangle(frame,(x,y) , (x+w, y+h) ,(0,255,0),thickness=3)\n",
    "    frame=rescal_frame(frame,(728,512))\n",
    "    cv2.imshow('Detecyed Face org',frame)\n",
    "#     cv2.imshow('thresh',thresh)\n",
    "#     cv2.imshow('gray',gray)\n",
    "#     cv2.imshow('gauss',gauss)  \n",
    "    \n",
    "    if cv2.waitKey(20) & 0xFF==ord('d'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "capture.release()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b915367",
   "metadata": {},
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdb3a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('modelMobnet3.h5')\n",
    "# model = load_model('model_DA.h5')\n",
    "model = load_model(r'C:\\Users\\user\\Desktop\\Project\\Glasses and Faces Detection\\Models\\model_DL_fine_tuned.h5')\n",
    "# model = load_model('Models/model_DA.h5')\n",
    "# model = load_model('Models/model_DL_frozen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "572c79b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 62720)             0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                4014144   \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,272,258\n",
      "Trainable params: 5,875,714\n",
      "Non-trainable params: 396,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8c62b8",
   "metadata": {},
   "source": [
    "# Face and Glasses Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25303b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 person\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "No Glasses\n",
      "There are 0 person\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "Glasses\n",
      "There are 0 person\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 455ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "No Glasses\n",
      "There are 1 person\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "No Glasses\n"
     ]
    }
   ],
   "source": [
    "har_file=cv2.CascadeClassifier('Har.xml')\n",
    "\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame=capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "        \n",
    "    frame=cv2.flip(frame,1)\n",
    "    frame=rescal_frame(frame,(224,224))\n",
    "    preprocessed_frame = preprocess_input(frame)\n",
    "\n",
    "    copy=frame.copy()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    gauss = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "    \n",
    "    \n",
    "    face_rect=har_file.detectMultiScale(gauss,scaleFactor=1.1,minNeighbors=3)\n",
    "    print(f\"There are {len(face_rect)} person\")\n",
    "    for (x,y,w,h) in face_rect:\n",
    "        cv2.rectangle(frame,(x-15,y-15) , (x+w+5, y+h+20) ,(0,255,0),thickness=3)\n",
    "        \n",
    "    croped=copy[y-35:y+h+35 ,x-35:x+w+35]\n",
    "    croped_2=rescal_frame(copy,(256,256))\n",
    "    preprocessed_frame_croped_2=rescal_frame(preprocessed_frame[y-20:y+h+20 ,x-5:x+w+35],(224,224))\n",
    "\n",
    "    prediction=model.predict( np.expand_dims(preprocessed_frame_croped_2, axis=0) )\n",
    "    \n",
    "    out=get_pred(prediction)\n",
    "    text_put(frame,out)\n",
    "    print(out)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#     cv2.imshow('Detecyed Face org',rescal_frame(frame,(512,512)))\n",
    "    cv2.imshow('Detecyed Face org',rescal_frame(frame,(512,512)))\n",
    "\n",
    "#     cv2.imshow('gray',gray)\n",
    "#     cv2.imshow('gauss',gauss)  \n",
    "#     cv2.imshow('croped',croped_2)\n",
    "    \n",
    "    cv2.imshow('croped',croped)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(20) & 0xFF==ord('d'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "capture.release()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
